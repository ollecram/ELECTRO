\appendix
\chapter{Tensors}
\label{ch:Tensors} 

\section{Change of basis}
Let $\{\vb{e}_1, \ldots, \vb{e}_n \}$ and $\{\tilde{\vb{e}}_1, \ldots, \tilde{\vb{e}}_n \}$ be two distinct bases\footnote{A basis is a maximal set of linearly independent vectors. All bases have the same number of elements. This number defines the dimensionality of the vector space.} of an $n$-dimensional vector space $E$.  
Let $A$ be the matrix whose element $A_{ij}$ is the coefficient of the unprimed basis vector $\vb{e}_j$ in the linear expansion of the primed basis vector $\tilde{\vb{e}}_i$ with respect to the unprimed basis    
\begin{align}
\label{eq:primed_from_unprimed}
\mqty[ \tilde{\vb{e}}_1 \\ \vdots \\ \tilde{\vb{e}}_j \\ \vdots \\ \tilde{\vb{e}}_n ] = \mqty|
A_{11}  &  \ldots  & A_{1j}  &  \cdots  & A_{1n} \\
\vdots  &  \cdots  & \vdots  &  \cdots  & \vdots \\
A_{i1}  &  \cdots  & A_{ij}  &  \cdots  & A_{in} \\
\vdots  &  \cdots  & \vdots  &  \cdots  & \vdots \\
A_{n1}  &  \cdots  & A_{nj}  &  \cdots  & A_{nn} |
\mqty[ \vb{e}_1 \\ \vdots \\ \vb{e}_i \\ \vdots \\ \vb{e}_n ]  
\end{align}

The $i$-th \textit{row} of $A$ thus contains the coefficients of the linear expansion of $\tilde{\vb{e}}_i$ with respect to the unprimed basis. 

In order to connect maximal sets of linearly independent vectors, the matrix $A$ must admit an \textit{inverse} hence it must be a \textit{regular} matrix, which is equivalent to require that its determinant must not be zero. The symmetric of \ref{eq:primed_from_unprimed} gives vectors of the primed basis as linear combinations of vectors of the unprimed basis. The matrix involved in that relation is the \textit{inverse} of $A$. Therefore

\begin{subequations}
\label{eq:twoway_basis_change}
\begin{align}
\tilde{\vb{e}}_i = A_{ij} \vb{e}_j \\
\vb{e}_i = A_{ij}^{-1} \tilde{\vb{e}}_j 
\end{align}
\end{subequations}



It is customary in applications to deal with \textit{orthogonal} bases, that is to say: bases whose elements are mutually orthogonal. For even greater convenience basis vectors may be chosen to be of \textit{unit norm}. 
Unfortunately, assuming to only deal with orthogonal bases hides some key aspects of the general theory of tensors\footnote{Part of this theory holds even for vector spaces where \textit{orthogonality} is impossible to define, because they are not equipped with a \textit{scalar product}.}.   

We will see that \textit{tensors} are a generalization of vectors and that most of their distinctive characteristics are associated to their behaviour with respect to a change of basis in the underlying vector spaces. The theory extends to finite dimensional vector spaces (heareafter FDVS) whose dimensionality $n$ can assume any finite value. Our strategy is to expose and motivate definitions with concrete examples, often presenting two-dimensional cases.

\subsection{Bases in two dimensions}
Here we propose a pair of orthonormal bases and a pair of non-orthonormal bases to study the matrices connecting the two bases in each pair.  

\subsection{Orthonormal bases in two dimensions}
In a two dimensional \textit{Euclidean}\footnote{A vector space equipped with a scalar product, in which therefore it is possible to define the \textit{length} of a vector and the \textit{angle} between two vectors.} vector space any two mutually orthogonal vectors of unit length provide a Cartesian basis. The transformation between any two Cartesian bases is defined by an \textit{orthogonal} $n \times n$ matrix whose columns and rows all have unit norm. In two dimensions the transformation is uniquely determined by a single parameter that we can always interpret as the \textit{angle} $\phi$ by which one basis is \textit{rotated} with respect to the other. 

Here the unit vectors $\{\vu{i}, \vu{j}\}$ and $\{\vu{i}', \vu{j}'\}$ belong to the unprimed and primed orthonormal basis, respectively.  

Simple geometric considerations lead to the following transformation matrices if we assume that the primed basis is obtained by a rotation of the unprimed basis by an angle $\phi$ which places the axis $\vu{i}'$ \textit{above} the axis $\vu{i}$ and the axis $\vu{j}'$ to the \textit{left} of the axis $\vu{j}$: 

\begin{subequations}
\label{eq:2D_orthobasis_xform}
\begin{align}
\label{eq:2D_orthobasis_xform_a}
\mqty[ \vu{i}' \\ \vb{j}'] &= \mqty|
+\cos(\phi) & +\sin(\phi) \\
-\sin(\phi) & +\cos(\phi) |
\mqty[ \,\vu{i}\, \\ \,\vu{j}\,]  = \:\;R(\phi)\:\, \mqty[ \,\vu{i}\, \\ \,\vu{j}\,] \\
\label{eq:2D_orthobasis_xform_b}
\mqty[ \,\vu{i}\, \\ \,\vu{j}\,] &= \mqty|
+\cos(\phi) & -\sin(\phi) \\
+\sin(\phi) & +\cos(\phi) |
\mqty[ \vu{i}' \\ \vu{j}']  = R^{-1}(\phi) \mqty[ \vu{i}' \\ \vu{j}']
\end{align}
\end{subequations}

In the following the rotation matrix of \ref{eq:2D_orthobasis_xform_a} will be referred to as $R(\phi)$  while the rotation matrix of \ref{eq:2D_orthobasis_xform_b} -- the inverse of the former -- will be referred to as $R(-\phi)$ or $R^{-1}(\phi)$.
\subsection{General bases in two dimensions}
Two exemplary non orthogonal bases in two dimensions are defined with respect to the orthonormal axes $\{\vu{i}, \vu{j}\}$ of a Cartesian basis, by use of the rotation matrices $R(\phi)$ and $R(-\phi)$ whose coefficients are given in \ref{eq:2D_orthobasis_xform_a} and \ref{eq:2D_orthobasis_xform_b}, respectively. We start with two pairs of orthogonal vectors, each pair obtained by a rotation of the basis $\vu{i}, \vu{j}$:  
\begin{align*}
\mqty[\vu{i}^+ \\ \vu{j}^+] &= \,R(+\phi) \mqty[ \,\vu{i}\, \\ \,\vu{j}\,] = \mqty|
+\cos(\phi) & +\sin(\phi) \\
-\sin(\phi) & +\cos(\phi) |
\mqty[ \,\vu{i}\, \\ \,\vu{j}\,]   \\
\mqty[\vu{i}^- \\ \vu{j}^-] &= \,R(-\phi) \mqty[ \,\vu{i}\, \\ \,\vu{j}\,] = \mqty|
+\cos(\phi) & -\sin(\phi) \\
+\sin(\phi) & +\cos(\phi) |
\mqty[ \,\vu{i}\, \\ \,\vu{j}\,]  
\end{align*}

Now we define two non-orthogonal bases from the above four vectors:
\begin{subequations}
\label{eq:2D_generalbases}
\begin{align}
\label{eq:2D_generalbasis_convergent}
\mqty[ \;\vb{e}_1\, \\ \;\vb{e}_2\,]       &= \mqty[\vu{i}^+ \\ \vu{j}^-]  = \mqty|
+\cos(\phi) & +\sin(\phi) \\
+\sin(\phi) & +\cos(\phi) |
\mqty[ \,\vu{i}\, \\ \,\vu{j}\,] \\
\label{eq:2D_generalbasis_divergent}
\mqty[ \,\tilde{\vb{e}}_1\, \\ \,\tilde{\vb{e}}_2\,] &= \mqty[\vu{i}^- \\ \vu{j}^+] = \mqty|
+\cos(\phi) & -\sin(\phi) \\
-\sin(\phi) & +\cos(\phi) |
\mqty[ \,\vu{i}\, \\ \,\vu{j}\,] 
\end{align}
\end{subequations}

In the following we assume\footnote{The matrices in \ref{eq:2D_generalbases} have zero determinant, hence no inverse for $\phi=\pi/4$.} $\phi < \pi/4$. 

The basis vectors in \ref{eq:2D_generalbasis_convergent} are \textit{convergent}, indeed
\begin{itemize}
\item $\vb{e}_1$ is placed at an angle $\phi$  above the axis $\vu{i}$;
\item $\vb{e}_2$ is placed at an angle $\phi$  on the right of the axis $\vu{j}$;
\item $\vb{e}_1$ and $\vb{e}_2$ make an angle $\theta = \pi/2 - 2 \phi < \pi/2$
\end{itemize} 
The basis vectors in \ref{eq:2D_generalbasis_divergent} are \textit{divergent}, indeed
\begin{itemize}
\item $\tilde{\vb{e}}_1$ is placed at an angle $\phi$  below the axis $\vu{i}$;
\item $\tilde{\vb{e}}_2$ is placed at an angle $\phi$  on the left of the axis $\vu{j}$;
\item $\tilde{\vb{e}}_1$ and $\tilde{\vb{e}}_2$ make an angle $\theta = \pi/2 + 2 \phi > \pi/2$
\end{itemize} 

In order to obtain the transformations between the primed and unprimed bases in \ref{eq:2D_generalbases} we need to compute the inverse of the matrices appearing in \ref{eq:2D_generalbasis_convergent} and\ref{eq:2D_generalbasis_divergent}, by which we can get the coordinates of the Cartesian basis $\{\vu{i}, \vu{j}\}$ with respect to $\{ \vb{e}_1, \, \vb{e}_2 \}$ and $\{ \tilde{\vb{e}}_1, \, \tilde{\vb{e}}_2 \}$. These computations\footnote{Making use of trigonometric identity $\cos 2A = \cos^2 A - \sin^2 A$ (Dwight 403.22).} 
yield

\begin{subequations}
\label{eq:2D_generalbases_inverses}
\begin{align}
\label{eq:2D_convergentbasis_inverse}
\mqty[ \,\vu{i}\, \\ \,\vu{j}\,] &= \frac{1}{\cos(2\phi)} \mqty|
+\cos(\phi) & -\sin(\phi) \\
-\sin(\phi) & +\cos(\phi) | 
\mqty[ \;\vb{e}_1\, \\ \;\vb{e}_2\,] \\
\label{eq:2D_divergentbasis_inverse}
\mqty[ \,\vu{i}\, \\ \,\vu{j}\,] &= \frac{1}{\cos(2\phi)} \mqty|
+\cos(\phi) & +\sin(\phi) \\
+\sin(\phi) & +\cos(\phi) | 
\mqty[ \,\tilde{\vb{e}}_1\, \\ \,\tilde{\vb{e}}_2\,] 
\end{align}
\end{subequations}

As expected, the transformations \ref{eq:2D_generalbases_inverses} become undefined when $\phi = \pi/4$, because in that case the axes of the \textit{convergent} basis $\{ \vb{e}_1, \, \vb{e}_2 \}$ collapse onto the diagonal of the first quadrant while the axes of the \textit{divergent} basis $\{  \tilde{\vb{e}}_1, \, \tilde{\vb{e}}_2 \}$ collapse onto the diagonal of the third quadrant. Substituting each identity in equation \ref{eq:2D_generalbases_inverses} in the corresponding identity of equation \ref{eq:2D_generalbases} we get

\begin{align*}
\mqty[ \,\tilde{\vb{e}}_1\, \\ \,\tilde{\vb{e}}_2\,] &= \frac{1}{\cos(2\phi)} \mqty|
+\cos(\phi) & -\sin(\phi) \\
-\sin(\phi) & +\cos(\phi) |  \mqty|
+\cos(\phi) & -\sin(\phi) \\
-\sin(\phi) & +\cos(\phi) | 
\mqty[ \;\vb{e}_1\, \\ \;\vb{e}_2\,] \\
\mqty[ \;\vb{e}_1\, \\ \;\vb{e}_2\,] &= \frac{1}{\cos(2\phi)} \mqty|
+\cos(\phi) & +\sin(\phi) \\
+\sin(\phi) & +\cos(\phi) |  \mqty|
+\cos(\phi) & +\sin(\phi) \\
+\sin(\phi) & +\cos(\phi) | 
\mqty[ \,\tilde{\vb{e}}_1\, \\ \,\tilde{\vb{e}}_2\,]  
\end{align*}

Performing the product of the two matrices appearing in each one of the above equations we finally get\footnote{Making use of the trigonometric identity $\sin(A+B) =  \sin A \cos B + \cos A \sin B$.} 

\begin{subequations}
\label{eq:2D_generalbases_xform}
\begin{align}
\label{eq:2D_convergent_to_divergent}
\mqty[ \,\tilde{\vb{e}}_1\, \\ \,\tilde{\vb{e}}_2\,] &= \frac{1}{\cos(2\phi)} \mqty|
1           & -\sin(2\phi) \\
-\sin(2\phi) &           1 | 
\mqty[ \;\vb{e}_1\, \\ \;\vb{e}_2\,]  = \:\;T(\phi)\:\; \mqty[ \;\vb{e}_1\, \\ \;\vb{e}_2\,] \\
\label{eq:2D_divergent_to_convergent}
\mqty[ \;\vb{e}_1\, \\ \;\vb{e}_2\,] &= \frac{1}{\cos(2\phi)} \mqty|
1           & \:\:\:\:\sin(2\phi) \\
\:\:\:\:\sin(2\phi) &           1 | 
\mqty[ \,\tilde{\vb{e}}_1\, \\ \,\tilde{\vb{e}}_2\,]  = T^{-1} (\phi) \mqty[ \,\tilde{\vb{e}}_1\, \\ \,\tilde{\vb{e}}_2\,]
\end{align}
\end{subequations}

The matrices in equations \ref{eq:2D_convergent_to_divergent} and \ref{eq:2D_divergent_to_convergent} (including the scaling factor $1/\cos(2\phi)$ that multiplies all their elements) are each other's \textit{inverse}. Indeed the product of the unscaled matrices yields the identity matrix multiplied by $\cos^2(2\phi)$, which is the \textit{squared reciprocal} of the scaling factor. 
In the following the matrix in \ref{eq:2D_convergent_to_divergent} will be denoted as $T(\phi)$  while the matrix in \ref{eq:2D_divergent_to_convergent} -- the inverse of the former -- will be denoted as $T(-\phi)$ or $T^{-1}(\phi)$.

\subsection{Coordinates transformation for vectors}
In the previous sections we have provided examples -- in two dimensions -- of a transformation between two orthonormal bases (equations \ref{eq:2D_orthobasis_xform}) and of a transformation between bases that are not orthogonal (equations \ref{eq:2D_generalbases_xform}). In this section we examine how a vector's coordinates in a given basis relate to coordinates of the same vector in another basis. In what follows, unprimed symbols denote the coordinates of some vector $\vb{v}$ in a given (unprimed) basis, while primed symbols denote the coordinates of the same vector in another (primed) basis. 
\subsubsection{Example 1 -- Orthogonal bases}
For definitness, take the two orthonormal bases of example \ref{eq:2D_orthobasis_xform}, so that 
\begin{align*}
\vb{v} &= x \;\vu{i}\; + y\; \vu{j}\; \\
\vb{v} &= x' \vu{i}' + y' \vu{j}'  
\end{align*} 

Holding the second equation, and replacing $\vu{i}$ and $\vu{j}$ in the first equation by their expansion with respect to the primed basis (equation \ref{eq:2D_orthobasis_xform_b}), the uniqueness of vector expansion with respect to that basis implies that coefficients of the same basis vector in the two sides must be equal. By this path we arrive at a formula expressing the primed coordinates as linear combinations of the unprimed coordinates. 

The same process can be repeated by holding the first equation, and replacing $\vu{i}'$ and $\vu{j}'$ in the second equation by their expansion with respect to the unprimed basis (equation \ref{eq:2D_orthobasis_xform_a}). By this path we get the unprimed coordinates as linear combinations of the primed coordinates. 

In matrix notation we thus obtain the following transformation rules for coordinates:  

\begin{subequations}
\label{eq:2D_orthocoord_xform}
\begin{align}
\label{eq:2D_orthocoord_xform_a}
\mqty[ x' \\ y'] &= \mqty|
+\cos(\phi) & +\sin(\phi) \\
-\sin(\phi) & +\cos(\phi) |
\mqty[ \,x\, \\ \,y\,] = \:\;R(\phi)\:\; \mqty[ \,x\, \\ \,y\,] \\
\label{eq:2D_orthocoord_xform_b}
\mqty[ \,x\, \\ \,y\,] &= \mqty|
+\cos(\phi) & -\sin(\phi) \\
+\sin(\phi) & +\cos(\phi) |
\mqty[ x' \\ y'] = R^{-1}(\phi) \mqty[ x' \\ y'] 
\end{align}
\end{subequations} 

The matrices connecting the primed coordinates to the unprimed are the same (see the transformations  \ref{eq:2D_orthobasis_xform}) that connect vectors of the primed basis to those of the unprimed basis. 

\subsubsection{Example 2 -- Non orthogonal bases}
By the same procedure, we now compute the coordinate transformations between the two bases of example \ref{eq:2D_generalbases_xform}, so that 
\begin{align*}
\vb{v} &= x_1 \;\vb{e}_1\; + x_2\; \vb{e}_2\; \\
\vb{v} &= \tilde{x}_1 \tilde{\vb{e}}_1 + \tilde{x}_2 \tilde{\vb{e}}_2  
\end{align*} 

Holding the second equation, and replacing $\vb{e}_1$ and $\vb{e}_2$ in the first equation by their expansion with respect to the primed basis (equation \ref{eq:2D_divergent_to_convergent}), the uniqueness of vector expansion with respect to that basis implies that coefficients of the same basis vector in the two sides must be equal. By this path we arrive at a formula expressing the primed coordinates as linear combinations of the unprimed coordinates. 

The same process can be repeated by holding the first equation, and replacing $\tilde{\vb{e}}_1$ and $\tilde{\vb{e}}_2$ in the second equation by their expansion with respect to the unprimed basis (equation \ref{eq:2D_convergent_to_divergent}). By this path we get the unprimed coordinates as linear combinations of the primed coordinates. 

In matrix notation we thus obtain the following transformation rules for coordinates:   

\begin{subequations}
\label{eq:2D_generalcoord_xform}
\begin{align}
\label{eq:2D_generalcoord_xform_a}
\mqty[ \tilde{x}_1 \\ \tilde{x}_2] &= \frac{1}{\cos(2\phi)} \mqty|
1           & -\sin(2\phi) \\
-\sin(2\phi) &           1 | 
\mqty[ \,x_1\, \\ \,x_2\,] = \:\;T(\phi)\:\, \mqty[ \,x_1\, \\ \,x_2\,] \\
\label{eq:2D_generalcoord_xform_b}
\mqty[ \,x_1\, \\ \,x_2\,] &= \frac{1}{\cos(2\phi)} \mqty|
1           & \:\:\:\:\sin(2\phi) \\
\:\:\:\:\sin(2\phi) &           1 | 
\mqty[ \tilde{x}_1 \\ \tilde{x}_2]  = T^{-1} (\phi) \mqty[ \tilde{x}_1 \\ \tilde{x}_2] 
\end{align}
\end{subequations}

Again, the matrices connecting the primed coordinates to the unprimed are the same (see the transformations  \ref{eq:2D_generalbases_xform}) that connect vectors of the primed basis to those of the unprimed basis.

\section{Forms}
We recall that a vector $\vb{v}$ lives in a \textit{vector space} $E$, the latter being defined with respect to a \textit{field} $K$ of \textit{scalars}. In most cases $K$ is the set of real numbers $\R$ or the set of complex numbers $\C$. A \textit{form} $\form{F}$ is a \textit{linear function} $\form{F} :E \rightarrow K$. 

Once a basis is introduced in $E$, a form is fully specified by the values it takes on the basis vectors. These are referred to as the \textit{components} of $\form{F}$ over the given basis. In order to distinguish between the components of a \textit{vector} from those of a \textit{form}, we use \textit{upper indices} on the former and \textit{lower indices} on the latter. We also use Einstein's convention, whereby summation is implied on terms where the same index appears on two factors in different positions. With these conventions, given a basis $\{\vb{e}_1, \ldots, \vb{e}_n\}$, we may write

\begin{subequations}
\label{eq:form_components}
\begin{align}   
f_i    &\equiv \form{F} (\vb{e}_i) \\
\vb{v} &= x^i \vb{e}_i \\
\form{F}(\vb{v}) &= \form{F}(x^i \vb{e}_i) \\
                 &= x^i  \form{F}(\vb{e}_i) \\
                 &= f_i x^i
\end{align}
\end{subequations}

\subsection{Dual space of $E$}
For a given $n$-dimensional vector space $E$ we may consider the set $E^*$ of all \textit{forms} acting on $E$. It is straightforward in $E^*$ to define linear combinations of forms, and to prove that $E^*$ is itself a vector space. Moreover, $E^*$ has the same dimension $n$ of $E$. This is proved by considering a basis $\{\vb{e}_1, \ldots, \vb{e}_n\}$ in $E$ and defining the following special forms (linear functions)

\begin{equation}   
\label{eq:form_basis}
\form{\theta}^i(\vb{e}_k) = \delta^i_k \\
\end{equation}

whereby

\begin{equation}
\begin{aligned}   
\label{eq:form_expansion}
\form{F} &= \form{F}(\vb{e}_i) \form{\theta}^i \\
         &= f_i \form{\theta}^i
\end{aligned}
\end{equation}

The set of $n$ forms $\form{\theta}^1, \ldots, \form{\theta}^n$ is clearly a basis in $E^*$ so it is called the \textit{dual basis} of $\{\vb{e}_1, \ldots, \vb{e}_n\}$. We interpret \ref{eq:form_expansion} by saying that a form $\form{F}$ has a unique set of coordinates $f_1, \ldots, f_n$ with respect to a basis in $E^*$.

Our next task is to determine the subordinate change on the dual basis of $E^*$ induced by a change of basis in $E$.

\subsection{Subordinate basis change in $E$ and $E^*$}

Let two bases $\:\vb{e}_1, \ldots, \vb{e}_n$ and $\tilde{\vb{e}}_1, \ldots, \tilde{\vb{e}}_n\:$ in $E$ -- hereafter referred to as the \textit{unprimed} and, respectively, the \textit{primed} basis -- be connected to each other by the transformation \textit{matrix} $A$ as in \ref{eq:twoway_basis_change}. Here, for typographic clarity we use the symbol $\tilde{A}$ (instead of $A^{-1}$) to denote the \textit{inverse} of $A$. For reasons that will become clear later on\footnote{For now, let take it as a convenient way to visually check that repeated indices denoting an implied summation should always be in different positions.} the \textit{column} index of the matrix is a \textit{superscript} while the \textit{row} index is a \textit{subscript}, so that 
\begin{subequations}
\label{eq:twoway_basis_change_supsub-notation}
\begin{align}
\tilde{\vb{e}}_i = A_i^j \vb{e}_j \\
\vb{e}_i = \tilde{A}_i^j \tilde{\vb{e}}_j 
\end{align}
\end{subequations}

With the above typographical conventions, the following identities hold separately with respect to the unprimed basis (\textit{left} column) and to the primed one (\textit{right} column):  
\begin{align} 
\label{eq:form_xform_a}
\form{\theta}^i(\vb{e}_k) &= \delta^i_k         &     \tilde{\form{\theta}}^i(\tilde{\vb{e}}_k) &= \delta^i_k \\  
\label{eq:form_xform_b}
   \vb{v}            &=  x^i \vb{e}_i           &     \vb{v}            &=  \tilde{x}^i \tilde{\vb{e}}_i   \\ 	     
\label{eq:form_xform_c}
   \form{F}(\vb{v})  &=  x^i \form{F}(\vb{e}_i) &     \form{F}(\vb{v})  &=  \tilde{x}^i \form{F}(\tilde{\vb{e}}_i) \\
\label{eq:form_xform_d}
   &=  x^i f_k \form{\theta}^k(\vb{e}_i)        &     &=  \tilde{x}^i \tilde{f}_k \form{\tilde{\theta}}^k(\tilde{\vb{e}}_i) \\
\label{eq:form_xform_e}
   &=  x^i f_k \delta^k_i                       &     &=  \tilde{x}^i \tilde{f}_k \delta^k_i \\
\label{eq:form_xform_f}
&=  f_i \, x^i                                  &     &=  \tilde{f}_i \, \tilde{x}^i   
\end{align}

We focus on the right identity in \ref{eq:form_xform_a}, in an attempt to get an expression for $\tilde{\form{\theta}}^i(\vb{e}_j)$ by use of the second identity in \ref{eq:twoway_basis_change_supsub-notation} 
\begin{align*} 
\tilde{\form{\theta}}^i(\tilde{\vb{e}}_k)       &=	\delta^i_k                \\
\tilde{\form{\theta}}^i(\tilde{A}^k_j \vb{e}_k) &=	\delta^i_k  \tilde{A}^k_j \\
\tilde{\form{\theta}}^i(\vb{e}_j)	            &=	\tilde{A}^i_j            
\end{align*}

The same can be repeated by starting with the left identity in \ref{eq:form_xform_a} and using the first identity in \ref{eq:twoway_basis_change_supsub-notation} 
\begin{align*} 
\form{\theta}^i(\vb{e}_k)           &=	\delta^i_k        \\
\form{\theta}^i(A^k_j \vb{e}_k)     &=	\delta^i_k  A^k_j \\
\form{\theta}^i(\tilde{\vb{e}}_j)	&=	A^i_j            
\end{align*}

The final step toward a direct relationship between forms of the dual bases is to apply \ref{eq:form_expansion} to the forms that constitute two such bases, whereby  

\begin{align} 
\label{eq:form_bases_xform_a}
\tilde{\form{\theta}}^i  &=  \tilde{\form{\theta}}^i(\vb{e}_j) \form{\theta}^j  &
\form{\theta}^i  &=  \form{\theta}^i(\tilde{\vb{e}}_j) \tilde{\form{\theta}}^j  \\
\label{eq:form_bases_xform_b}
\tilde{\form{\theta}}^i  &=  \tilde{A}^i_j \form{\theta}^j  &
\form{\theta}^i  &=  A^i_j \tilde{\form{\theta}}^j 
\end{align}
 
The transformations \ref{eq:form_bases_xform_b} translate in the context of $E^*$ the transformations \ref{eq:twoway_basis_change_supsub-notation} between bases of $E$. Comparing  these equations we note that the role of the same matrices $A$ and $\tilde{A}$ is \quotes{inverted}. The same happens with the transformation of coordinates.


\subsection{Subordinate coordinates change in $E$ and $E^*$}
A direct relationship between the \textit{coordinates} of a form $\form{F}$ with respect to different bases can now be obtained using \ref{eq:form_bases_xform_b} and \ref{eq:form_expansion}

\begin{align} 
\label{eq:form_coordinates_xform_a}
\form{F} &= f_i \form{\theta}^i                & 	\form{F} &= \tilde{f}_i \tilde{\form{\theta}}^i  \\  
\label{eq:form_coordinates_xform_b}
\form{F} &= f_k A^k_i \tilde{\form{\theta}}^i  & 	\form{F} &= \tilde{f}_k \tilde{A}^k_i \form{\theta}^i
\end{align}

Confronting the left of \ref{eq:form_coordinates_xform_a} with the right of \ref{eq:form_coordinates_xform_b}  then the right of \ref{eq:form_coordinates_xform_a} with the left of \ref{eq:form_coordinates_xform_b} we obtain\footnote{Because the coefficients of the expansion of a vector-space element are unique.}

\begin{align} 
\label{eq:form_coordinates_xform_c}
f_i          &=  \tilde{A}^k_i \tilde{f}_k  \\
\label{eq:form_coordinates_xform_d}
\tilde{f}_i  &=  A^k_i f_k
\end{align}

According to \ref{eq:form_coordinates_xform_c} and \ref{eq:form_coordinates_xform_d}, the \textit{coordinates} of a \textit{form} transform differently than those of a vector, indeed
\begin{itemize}
\item In the vector space $E$, the matrix $A$ is the one transforming the unprimed basis vectors (and \textit{vector coordinates}) to the primed \textit{basis vectors} and \textit{vector coordinates}, while the inverse matrix $\tilde{A}$ transforms in the opposite direction.
\item In the dual space $E^*$, the same matrices $A$ and $\tilde{A}$ perform transformations between \textit{basis forms} and \textit{form  coordinates} with inverted roles: $A$ transforms primed to unprimed (basis forms and form coordinates), while the inverse matrix $\tilde{A}$ transforms in the opposite direction.  
\end{itemize} 

   
